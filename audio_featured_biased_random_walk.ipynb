{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import random\n",
    "from playlist import *\n",
    "from collections import defaultdict\n",
    "from numpy.random import choice\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import os\n",
    "import random\n",
    "import playlist\n",
    "reload(playlist)\n",
    "\n",
    "# client_credentials_manager = SpotifyClientCredentials()\n",
    "# sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "\n",
    "# results = sp.search(q='weezer', limit=20)\n",
    "# for i, t in enumerate(results['tracks']['items']):\n",
    "#     print(' ', i, t['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_list = playlist.get_playlist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(playlist_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.getsizeof(playlist_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_tracks(playlist):\n",
    "#     track_list = set([])\n",
    "#     for i in range(playlist['num_tracks']):\n",
    "#         track_list.add(playlist['tracks'][i]['track_uri'])\n",
    "#     return track_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# track_audio_features = {}\n",
    "# for i in range (len(playlist_list)):\n",
    "#         playlist = playlist_list[i]\n",
    "#         for j in range(playlist['num_tracks']):\n",
    "#             track_uri = playlist['tracks'][j]['track_uri']\n",
    "#             if track_uri not in track_audio_features:\n",
    "#                 track_audio_features[track_uri] = sp.audio_features([track_uri])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gzip\n",
    "# import pickle\n",
    "\n",
    "# with gzip.open('audio_features_1K.pickle.gz','wb') as output:\n",
    "#     pickle.dump(track_audio_features ,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gzip\n",
    "# import pickle\n",
    "\n",
    "# with gzip.open(\"audio_features_1K_p2.pickle.gz\", \"rb\") as inp:\n",
    "#     track_audio_features = pickle.load(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "audio_df = pd.read_csv('playlist-tracks.tracksFeatureCache.csv', index_col = 'uri')\n",
    "# audio_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_df = audio_df[['acousticness', 'danceability', 'duration_ms', 'energy',\n",
    "        'instrumentalness', 'key', 'liveness', 'loudness', 'mode',\n",
    "       'speechiness', 'tempo', 'time_signature',\n",
    "       'valence']]\n",
    "audio_df = audio_df.astype(float)\n",
    "audio_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sp.audio_features(['spotify:track:20ORwCJusz4KS2PbTPVNKo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sp.audio_analysis('spotify:track:20ORwCJusz4KS2PbTPVNKo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sp.artist('spotify:artist:2Hjj68yyUPiC0HKEOigcEp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_df = pd.DataFrame(track_audio_features).T\n",
    "# audio_df = audio_df[['acousticness', 'danceability', 'duration_ms', 'energy',\n",
    "#         'instrumentalness', 'key', 'liveness', 'loudness', 'mode',\n",
    "#        'speechiness', 'tempo', 'time_signature',\n",
    "#        'valence']]\n",
    "# audio_df = audio_df.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_df = audio_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalised panda data frame\n",
    "from sklearn import preprocessing\n",
    "\n",
    "x = audio_df.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "new_audio_df = pd.DataFrame(x_scaled)\n",
    "new_audio_df.index = audio_df.index\n",
    "audio_df = new_audio_df\n",
    "# new_audio_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_track_embedding(track_uri):\n",
    "    return audio_df.loc[track_uri].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_track_embedding('spotify:track:0uqPG793dkDDN7sCUJJIVC').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_playlist_embedding = {}\n",
    "num_missing_tracks = 0\n",
    "\n",
    "def get_playlist_embedding(playlist_id):\n",
    "    global num_missing_tracks\n",
    "    # check if already in cache \n",
    "    if playlist_id in cached_playlist_embedding:\n",
    "        return cached_playlist_embedding[playlist_id]\n",
    "\n",
    "    embedding_list = []\n",
    "    for i in range(playlist_list[playlist_id]['num_tracks']):\n",
    "        track_uri = playlist_list[playlist_id]['tracks'][i]['track_uri']\n",
    "    #     print(type(track_df.loc[track_uri]))\n",
    "        if track_uri in audio_df.index:\n",
    "            embedding_list.append(get_track_embedding(track_uri))\n",
    "        else:\n",
    "            num_missing_tracks += 1\n",
    "    embedding = np.mean(embedding_list, axis = 0)\n",
    "    embedding = embedding.reshape(1, -1)\n",
    "    norm_embedding = np.linalg.norm(embedding)\n",
    "    # put in the cache\n",
    "    cached_playlist_embedding[playlist_id] = (embedding, embedding/norm_embedding)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for playlist_id in tqdm(range(len(playlist_list))):\n",
    "    get_playlist_embedding(playlist_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print num_missing_tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dot = np.inner\n",
    "_linear_cache = tuple([get_playlist_embedding(playlist_id)\n",
    "                       for playlist_id in range(len(playlist_list))])\n",
    "\n",
    "def cal_similarity(playlist_id_1, playlist_id_2):\n",
    "#     a, norm_a = get_playlist_embedding(playlist_id_1)\n",
    "#     b, norm_b = get_playlist_embedding(playlist_id_2)\n",
    "    _, normed_a = _linear_cache[playlist_id_1]\n",
    "    _, normed_b = _linear_cache[playlist_id_2]\n",
    "    \n",
    "    X = _dot(normed_a, normed_b)\n",
    "#     X = _dot(a, b) / (norm_a * norm_b)\n",
    "    return X.item()\n",
    "\n",
    "# 10x slower\n",
    "def cal_similarity2(playlist_id_1, playlist_id_2):\n",
    "    similarity = sklearn.metrics.pairwise.cosine_similarity(get_playlist_embedding(playlist_id_1)[0], \n",
    "                                                            get_playlist_embedding(playlist_id_2)[0])\n",
    "#     similarity = sklearn.metrics.pairwise.euclidean_distances(get_playlist_embedding(playlist_id_1).reshape(1, -1), \n",
    "#                                                                 get_playlist_embedding(playlist_id_2).reshape(1, -1))\n",
    "#         return similarity[0][0]\n",
    "    return similarity[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(cal_similarity(0, 1))\n",
    "# print(cal_similarity2(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "cal_similarity(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "cal_similarity2(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see https://stackoverflow.com/questions/34968722/how-to-implement-the-softmax-function-in-python\n",
    "def slow_softmax_sample(x):\n",
    "    # but does not change the answer\n",
    "    x = np.exp(x - np.max(x))\n",
    "    prob_dis = x / float(sum(x))\n",
    "    return int(choice(range(len(x)), 1, p=prob_dis))\n",
    "\n",
    "# https://timvieira.github.io/blog/post/2014/07/31/gumbel-max-trick/\n",
    "def softmax_sample(x):\n",
    "    cdf = np.exp(x - x.max()).cumsum()\n",
    "    z = cdf[-1]\n",
    "    u = np.random.uniform(0,1)\n",
    "    return cdf.searchsorted(u * z)\n",
    "\n",
    "def fast_softmax_sample(x):\n",
    "    z = np.random.gumbel(loc=0, scale=1, size=x.shape)\n",
    "    return (x + z).argmax(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "slow_softmax_sample(np.array([1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "softmax_sample(np.array([1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "fast_softmax_sample(np.array([1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biased_audio_random_walk_playlist(query,g,dropped_track_id, beta = 1000):\n",
    "    \n",
    "    N = 10000\n",
    "    totSteps = 0\n",
    "    nHighVisited = 0\n",
    "    nt = 200\n",
    "    nv = 5\n",
    "    num_visits = defaultdict(int)\n",
    "\n",
    "    weight_cache = {}\n",
    "    def cal_weight(edge):\n",
    "        if edge in weight_cache:\n",
    "            return weight_cache[edge]\n",
    "\n",
    "        val = cal_similarity(query,edge)\n",
    "        weight_cache[edge] = val\n",
    "        return val\n",
    "\n",
    "    while totSteps < N and nHighVisited < nt: \n",
    "        currPlaylist = query\n",
    "        # Number of iterations\n",
    "        currSteps = 5\n",
    "        for i in range(currSteps):\n",
    "            # takes 1 step (from a playlist to track)\n",
    "            edges = list(g[currPlaylist])\n",
    "            if currPlaylist == query:\n",
    "                edges.remove(dropped_track_id)\n",
    "            currTrack = random.choice(edges)\n",
    "            # takes 1 step (from a track to playlist)\n",
    "            edges = list(g[currTrack])\n",
    "            if currTrack == dropped_track_id:\n",
    "                edges.remove(query)\n",
    "#             weights = [f(edge) for edge in edges]\n",
    "            weights = [cal_weight(edge) for edge in edges]\n",
    "            weights_np = np.asarray(weights)\n",
    "\n",
    "# see https://stackoverflow.com/questions/34968722/how-to-implement-the-softmax-function-in-python\n",
    "#           # this bit makes it more stable numerically\n",
    "            max_weight = np.max(weights_np)\n",
    "            weights_np -= max_weight\n",
    "            # but does not change the answer\n",
    "            weights_np = np.exp(beta * weights_np)\n",
    "\n",
    "            prob_dis = weights_np / float(sum(weights_np))\n",
    "            currPlaylist = int(choice(edges, 1, p=prob_dis))\n",
    "            num_visits[currTrack] += 1\n",
    "            if num_visits[currTrack] == nv:\n",
    "                nHighVisited += 1\n",
    "        totSteps += currSteps\n",
    "    return num_visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g, tracks_dict, tracks_id_dict = playlist.make_graph_dict(playlist_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_most_visited_playlist(playlist_list, playlist_id):\n",
    "    dropped_track_id = random.choice(tuple(g[playlist_id]))\n",
    "\n",
    "    if len(g[playlist_id]) < 5:\n",
    "        return None, None\n",
    "    num_visits = biased_audio_random_walk_playlist(playlist_id, g, dropped_track_id)\n",
    "    suggested_ids = sorted(num_visits, key=num_visits.get, reverse=True)\n",
    "    return dropped_track_id, suggested_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%prun\n",
    "# cal_most_visited_playlist(playlist_list, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_true_ids, all_suggested_ids = cal_most_visited(playlist_list)\n",
    "all_true_ids, all_suggested_ids = playlist.process_playlists(cal_most_visited_playlist,\n",
    "                                                             playlist_list, multiprocess=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savez_compressed('audio_featured_biased_100k_500_result.npz',all_true_ids = all_true_ids, \n",
    "#                    all_suggested_ids = all_suggested_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = playlist.cal_results(playlist_list, all_true_ids, all_suggested_ids)\n",
    "filename = 'results%d_audio_featured_biased_random_walk_10K.txt' % (len(playlist_list),)\n",
    "with open(filename, 'w') as output:\n",
    "    output.write(str(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# np.any(audio_df.isna(), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(audio_df.fillna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "weights = [cal_similarity(0, 1+i) for i in range(10)]\n",
    "weights_np = np.asarray(weights)\n",
    "prob_dis = weights_np / float(sum(weights_np))\n",
    "plt.plot(prob_dis, label=\"flat\")\n",
    "for beta in [1,2,5,10,50]:\n",
    "    weights_np = np.asarray(weights)\n",
    "    # this bit makes it more stable numerically\n",
    "    max_weight = np.max(weights_np)\n",
    "    weights_np -= max_weight\n",
    "    # but does not change the answer\n",
    "    weights_np = np.exp(beta * weights_np)\n",
    "\n",
    "    prob_dis = weights_np / float(sum(weights_np))\n",
    "    plt.plot(prob_dis, label=\"beta=\" + str(beta))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
