{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime\n",
    "# import snap\n",
    "import random\n",
    "import os\n",
    "import playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_list = playlist.get_playlist_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(playlist_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.getsizeof(playlist_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tracks(playlist):\n",
    "    track_list = []\n",
    "    for i in range(playlist['num_tracks']):\n",
    "        track_list.append(playlist['tracks'][i]['track_uri'])\n",
    "    return track_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_track_artist_dict(playlist_list):\n",
    "    track_artist_dict = {}\n",
    "    for playlist in playlist_list:\n",
    "        for track in playlist['tracks']:\n",
    "            track_artist_dict[track['track_uri']] = track['artist_uri']\n",
    "    return track_artist_dict\n",
    "\n",
    "track_artist_dict = make_track_artist_dict(playlist_list)\n",
    "\n",
    "def get_track_uri_artist(track_uri):\n",
    "    return track_artist_dict.get(track_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g, tracks_dict, tracks_id_dict = playlist.make_graph_dict(playlist_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "def basic_random_walk_track_neighbors(query, g, dropped_track_id):\n",
    "    N = 10000\n",
    "    totalSteps = 0\n",
    "    num_visits = defaultdict(int)\n",
    "    \n",
    "    while totalSteps < N:\n",
    "        currTrack = query\n",
    "        currSteps = 5\n",
    "        for i in range(currSteps):\n",
    "            # takes 1 step (from a track to playlist)\n",
    "            edges = list(g[currPlaylist])\n",
    "            if currPlaylist == query:\n",
    "                edges.remove(dropped_track_id)\n",
    "            currTrack = random.choice(edges)\n",
    "            # takes 1 step (from a playlist to track)\n",
    "            edges = list(g[currTrack])\n",
    "            if currTrack == dropped_track_id:\n",
    "                edges.remove(query)\n",
    "            currTrack = random.choice(edges)\n",
    "            num_visits[currTrack] += 1\n",
    "        totalSteps += currSteps\n",
    "    return num_visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numbers_up_to(n):\n",
    "    for i in range(n):\n",
    "        yield i, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, j in numbers_up_to(4):\n",
    "    print(k+j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g, dropped_track_id,track_id_dict,tracks_dict  = make_graph_drop_edge(playlist_list, 20, 3)\n",
    "# edges = list(g.GetNI(0).GetOutEdges())\n",
    "# print edges\n",
    "# print(dropped_track_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_neighbors(graph, track_id, T):\n",
    "    num_visit_dict = basic_random_walk_track_neighbors(track_id, graph)\n",
    "    suggested_ids = sorted(num_visit_dict, key=num_visit_dict.get, reverse=True)\n",
    "    if T < len(suggested_ids):\n",
    "        return suggested_ids[:T]\n",
    "    else:\n",
    "        print 'The number of track neighbors are smaller than the amount asked'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = get_random_neighbors(g, 2000, 5)\n",
    "# print result\n",
    "# print type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_negative_neighbors(graph, track_id, T, L, sample_num):\n",
    "    if L < T and L > sample_num:\n",
    "        top_t_suggested_ids = get_random_neighbors(graph, track_id, T)\n",
    "        top_t_suggested_ids.reverse()\n",
    "        negative_neighbors_list = np.random.choice(top_t_suggested_ids[:L], sample_num, replace=False)\n",
    "    else:\n",
    "        print 'error'\n",
    "    return negative_neighbors_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ran_result = get_random_negative_neighbors(g, 2000, 5, 3, 2)\n",
    "# print ran_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_track_uri_from_track_id(given_track_id, track_id_dict):\n",
    "    return track_id_dict[given_track_id]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = get_track_uri_from_track_id(1970, track_id_dict)\n",
    "# print res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOVE THE CODE TO THIS FOLDER\n",
    "\n",
    "\n",
    "track_w2vf_df = pd.read_csv(\"word2vecf-features.txt\", skiprows=1, header=None, sep=' ')\n",
    "track_w2vf_df = track_w2vf_df.set_index(0)\n",
    "track_w2vf_df = track_w2vf_df.drop(columns=[track_w2vf_df.shape[1]])\n",
    "track_w2vf_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_w2vf_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_w2vf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ix = index\n",
    "# track_df.ix['spotify:track:4eLSCSELtKxZwXnFbNLXT5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# np.array(track_w2vf_df.loc['spotify:track:4eLSCSELtKxZwXnFbNLXT5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_id_to_vector(given_track_id, track_id_dict, track_df):\n",
    "    track_uri = get_track_uri_from_track_id(given_track_id, track_id_dict)\n",
    "    w2vf_vector = np.array(track_df.loc[track_uri])\n",
    "    return w2vf_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector = track_id_to_vector(2500, track_id_dict, track_w2vf_df)\n",
    "# print vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_id_list_to_matrix(given_track_id_list, track_id_dict, track_df):\n",
    "    vector_list = []\n",
    "    for given_track_id in given_track_id_list:\n",
    "        vector_list.append(track_id_to_vector(given_track_id, track_id_dict, track_df))\n",
    "    return np.vstack(vector_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix = track_id_list_to_matrix([2000,2010,3000], track_id_dict, track_w2vf_df)\n",
    "# print matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_track_dicts(playlist_list):\n",
    "    tracks_dict = {}\n",
    "    next_track_id = len(playlist_list)\n",
    "    for playlist_id, playlist in enumerate(playlist_list):\n",
    "        track_list = get_tracks(playlist)\n",
    "        track_list = sorted(track_list)\n",
    "        \n",
    "        for track_index, track_uri in enumerate(track_list):\n",
    "            if track_uri not in tracks_dict:\n",
    "                tracks_dict[track_uri] = next_track_id\n",
    "                next_track_id += 1\n",
    "    track_id_dict = dict(zip(tracks_dict.values(), tracks_dict.keys()))\n",
    "    return track_id_dict, tracks_dict\n",
    "\n",
    "def get_dropped_track_id(track_id_dict, playlist_list, playlist_id, dropped_track_index):\n",
    "    playlist = playlist_list[playlist_id]\n",
    "    tracks = get_tracks(playlist)\n",
    "    tracks.sort()\n",
    "    track_uri = tracks[dropped_track_index]\n",
    "    return tracks_dict[track_uri]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_id_dict, tracks_dict = make_track_dicts(playlist_list)\n",
    "\n",
    "def generate_one_training_data(playlist_list, track_df):\n",
    "    track_ids_in_playlist_list = []\n",
    "    # 5 tries\n",
    "    for i in range(5):\n",
    "        playlist_id = random.randrange(len(playlist_list))\n",
    "        dropped_track_index = random.randrange(playlist_list[playlist_id]['num_tracks'])\n",
    "        dropped_track_id = get_dropped_track_id(track_id_dict, playlist_list, playlist_id, dropped_track_index)\n",
    "    #         print dropped_track_id\n",
    "    #         print track_id_dict\n",
    "        dropped_track_uri = track_id_dict[dropped_track_id]\n",
    "        if dropped_track_uri not in track_w2vf_df.index:\n",
    "            continue\n",
    "        track_vector = track_id_to_vector(dropped_track_id, track_id_dict, track_df)\n",
    "        tracks = sorted(get_tracks(playlist_list[playlist_id]))\n",
    "        for j, track_uri in enumerate(tracks):\n",
    "            if j == dropped_track_index:\n",
    "                continue\n",
    "            if track_uri not in track_w2vf_df.index:\n",
    "                continue\n",
    "            track_ids_in_playlist_list.append(tracks_dict[track_uri])\n",
    "        if not track_ids_in_playlist_list:\n",
    "            continue\n",
    "        query_matrix = track_id_list_to_matrix(track_ids_in_playlist_list, track_id_dict, track_df)\n",
    "        query_vector = query_matrix.mean(0)\n",
    "        return track_vector, query_vector\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tnrange\n",
    "\n",
    "sample_row_number = len(tracks_dict)\n",
    "track_vector_rows = np.empty((sample_row_number, 200))\n",
    "query_vector_rows = np.empty((sample_row_number, 200))\n",
    "for ii in tnrange(sample_row_number):\n",
    "    track_vector, query_vector = generate_one_training_data(playlist_list, track_w2vf_df)\n",
    "    if track_vector is None:\n",
    "        continue\n",
    "    track_vector_rows[ii,:] = track_vector\n",
    "    query_vector_rows[ii,:] = query_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(track_vector_rows.shape)\n",
    "print(query_vector_rows.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tracks_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('torch_query_track_vectors_%d_playlist_new' % (len(playlist_list),), track_vector_rows=track_vector_rows, query_vector_rows=query_vector_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savez_compressed('torch_query_track_vectors_1k_playlist', track_vector_rows=track_vector_rows, query_vector_rows=query_vector_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(get_tracks(playlist_list[331]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_array = np.empty((0, 100))\n",
    "\n",
    "# for line in data_array:\n",
    "#     result = do_stuff(line)\n",
    "#     result_array = np.append(result_array, [result], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_vector, query_matrix = generate_one_training_data(playlist_list, track_w2vf_df)\n",
    "print(track_vector.shape)\n",
    "print(query_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(200, 50)\n",
    "        self.fc2 = nn.Linear(50, 50)\n",
    "        self.fc3 = nn.Linear(50, 200)\n",
    "\n",
    "    def forward(self, vi):\n",
    "        ui = self.fc1(vi)\n",
    "        ui_rel = F.relu(ui)\n",
    "        uui = F.relu(self.fc2(ui_rel))\n",
    "        predictaed_vi = self.fc3(uui)\n",
    "        return predictaed_vi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm import tnrange\n",
    "\n",
    "def train(model, optimizer, loader, num_epochs):\n",
    "#     loader does the job of these 3 lines\n",
    "#     track_vector, query_vector = generate_one_training_data(playlist_list, track_w2vf_df)\n",
    "#     target = torch.from_numpy(track_vector).float()\n",
    "#     data = torch.from_numpy(query_vector).float()\n",
    "    model.train()\n",
    "    losses = []\n",
    "    total_steps = len(loader.dataset)/loader.batch_size\n",
    "    for epoch in tnrange(num_epochs):\n",
    "        for batch_idx, (data, target) in tqdm(enumerate(loader),total=total_steps,leave=False):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            output_norm = output.norm(p=2, dim=-1)\n",
    "            cosine_loss = F.mse_loss(output/output_norm.view(-1, 1),\n",
    "                              target/target.norm(p=2, dim=-1).view(-1, 1))\n",
    "            loss = cosine_loss + 0.001*output_norm.mean()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if (batch_idx % 100) == 0:\n",
    "                losses.append(cosine_loss.item())\n",
    "        print(np.mean(losses[-total_steps/100:]))\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=5e-3, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load('torch_query_track_vectors_50000_playlist.npz')\n",
    "# train_data = np.load('torch_query_track_vectors_100k_playlist.npz')\n",
    "# data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "# make it to torch dataset\n",
    "dataset = torch.utils.data.TensorDataset(\n",
    "    torch.from_numpy(train_data['query_vector_rows']).float(), \n",
    "    torch.from_numpy(train_data['track_vector_rows']).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(dataset, batch_size = 32, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "losses = train(model, optimizer, loader, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_data_mse = np.mean((train_data['query_vector_rows']-train_data['track_vector_rows'])**2)\n",
    "avg_data_cosine = np.mean((train_data['query_vector_rows']/np.linalg.norm(train_data['query_vector_rows'], axis=-1).reshape(-1, 1)\n",
    "                           -\n",
    "                           train_data['track_vector_rows']/np.linalg.norm(train_data['track_vector_rows'], axis=-1).reshape(-1, 1))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'neural_network.torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('neural_network.torch'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy.spatial.distance\n",
    "# from tqdm import tqdm_notebook as tqdm\n",
    "# from tqdm import tnrange\n",
    "# a = train_data['query_vector_rows']\n",
    "# b = train_data['track_vector_rows']\n",
    "# num = a.shape[0]\n",
    "# s = 0.0\n",
    "# for i in tnrange(num):\n",
    "#     s += scipy.spatial.distance.cosine(a[i,:], b[i,:])\n",
    "# s/num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['query_vector_rows'][0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(avg_data_mse)\n",
    "print(avg_data_cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses, label='training loss')\n",
    "plt.plot([avg_data_cosine]*len(losses), label='original cosine similarity')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc3.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = model.fc1.weight.detach().numpy()\n",
    "b = model.fc1.bias.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2 = model.fc2.weight.detach().numpy()\n",
    "b2 = model.fc2.bias.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_query_vector_rows = np.maximum(0, np.dot(train_data['query_vector_rows'], w.T) + b)\n",
    "proj_track_vector_rows = np.maximum(0, np.dot(train_data['track_vector_rows'], w.T) + b)\n",
    "proj_query_vector_rows = np.dot(proj_query_vector_rows, w2.T) + b2\n",
    "proj_track_vector_rows = np.dot(proj_track_vector_rows, w2.T) + b2\n",
    "\n",
    "a = proj_query_vector_rows\n",
    "b = proj_track_vector_rows\n",
    "avg_data_cosine = np.mean((a/np.linalg.norm(a, axis=-1).reshape(-1, 1)\n",
    "                           -\n",
    "                           b/np.linalg.norm(b, axis=-1).reshape(-1, 1))**2)\n",
    "print(avg_data_cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_dict, tracks_id_dict = playlist.make_tracks_dict(playlist_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "track_df = track_w2vf_df.loc[tracks_dict.keys()]\n",
    "track_array = track_df.values\n",
    "\n",
    "# transformed_array = model(torch.Tensor(track_array))\n",
    "# transformed_array = np.dot(track_array, w.T)\n",
    "transformed_array = np.maximum(0, np.dot(track_array, w.T) + b)\n",
    "transformed_array = np.dot(transformed_array, w2.T)\n",
    "\n",
    "track_array = transformed_array #.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(track_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_query(tracks, drop_track_index, track_df, track_array):\n",
    "    track_indices = [track_df.index.get_loc(track_uri)\n",
    "                     for i, track_uri in enumerate(tracks) if i != drop_track_index]\n",
    "    return np.mean(track_array[track_indices, :], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tracks = get_tracks(playlist_list[0])\n",
    "# make_query(tracks, 0, track_df, track_array).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from tqdm import tnrange\n",
    "import random\n",
    "\n",
    "def cal_knn(k, track_array, track_df, tracks_dict):\n",
    "    nbrs = NearestNeighbors(n_neighbors=k, metric='cosine', n_jobs=1).fit(track_array)\n",
    "    all_true_ids = []\n",
    "    all_distances = []\n",
    "    all_suggested_ids = []\n",
    "\n",
    "    for i in tnrange(10000): #len(playlist_list)):\n",
    "        tracks = playlist.get_tracks(playlist_list[i])\n",
    "        if len(tracks) < 5:\n",
    "            continue\n",
    "        dropped_track_index = random.choice(range(len(tracks)))\n",
    "        true_track_uri = tracks[dropped_track_index]\n",
    "        true_id = tracks_dict[true_track_uri]\n",
    "        all_true_ids.append(true_id)\n",
    "\n",
    "        query = make_query(tracks, dropped_track_index, track_df, track_array)\n",
    "        distances, suggested_index_array = nbrs.kneighbors(query.reshape(1,-1))\n",
    "        suggested_ids = [tracks_dict[track_df.index[index]]\n",
    "                         for index in suggested_index_array.flatten()]\n",
    "        all_distances.append(distances)\n",
    "        all_suggested_ids.append(suggested_ids)\n",
    "#         if (i % 1000) == 1:\n",
    "#             print(i)\n",
    "#             print(playlist.cal_results(playlist_list, all_true_ids, all_suggested_ids))\n",
    "    return all_true_ids, all_distances, all_suggested_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_true_ids, all_distances, all_suggested_ids = cal_knn(500, track_array, track_df, tracks_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savez('ids_neural_network_50k.npz', all_true_ids=all_true_ids, all_distances=all_distances, all_suggested_ids=all_suggested_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.load('ids_neural_network_50k.npz')\n",
    "all_true_ids=x['all_true_ids']\n",
    "all_suggested_ids=x['all_suggested_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_true_ids.shape\n",
    "all_suggested_ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist.cal_results(playlist_list, all_true_ids, all_suggested_ids.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = playlist.cal_results(playlist_list, all_true_ids, all_suggested_ids.tolist())\n",
    "filename = 'results%d_w2v_neural_networks_enc.txt' % (len(playlist_list),)\n",
    "with open(filename, 'w') as output:\n",
    "    output.write(str(results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
